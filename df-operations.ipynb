{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191004c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2be28d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2282bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf8baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data path\n",
    "data_path = \"Exercise Files/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983d045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load utilization.json\n",
    "file_path = data_path + \"/utlization.json\"\n",
    "df1 = spark.read.format(\"json\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0049267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show df1\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "708f77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load location_temp.csv\n",
    "file_path = data_path + \"/location_temp.csv\"\n",
    "df2 = spark.read.format(\"csv\").option(\"header\", \"true\").load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bec99a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:53:06|       loc0|          27|\n",
      "|03/04/2019 19:58:06|       loc0|          28|\n",
      "|03/04/2019 20:03:06|       loc0|          30|\n",
      "|03/04/2019 20:08:06|       loc0|          27|\n",
      "|03/04/2019 20:13:06|       loc0|          27|\n",
      "|03/04/2019 20:18:06|       loc0|          27|\n",
      "|03/04/2019 20:23:06|       loc0|          29|\n",
      "|03/04/2019 20:28:06|       loc0|          32|\n",
      "|03/04/2019 20:33:06|       loc0|          35|\n",
      "|03/04/2019 20:38:06|       loc0|          32|\n",
      "|03/04/2019 20:43:06|       loc0|          28|\n",
      "|03/04/2019 20:48:06|       loc0|          28|\n",
      "|03/04/2019 20:53:06|       loc0|          32|\n",
      "|03/04/2019 20:58:06|       loc0|          34|\n",
      "|03/04/2019 21:03:06|       loc0|          33|\n",
      "|03/04/2019 21:08:06|       loc0|          27|\n",
      "|03/04/2019 21:13:06|       loc0|          28|\n",
      "|03/04/2019 21:18:06|       loc0|          33|\n",
      "|03/04/2019 21:23:06|       loc0|          28|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show df2\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef5cae8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpu_utilization',\n",
       " 'event_datetime',\n",
       " 'free_memory',\n",
       " 'server_id',\n",
       " 'session_count']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list column names\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d08a38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cpu_utilization: double (nullable = true)\n",
      " |-- event_datetime: string (nullable = true)\n",
      " |-- free_memory: double (nullable = true)\n",
      " |-- server_id: long (nullable = true)\n",
      " |-- session_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schema\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandafy a DataFrame\n",
    "df_pandas = df1.toPandas()\n",
    "df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a223a4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      100|           47|\n",
      "|      100|           43|\n",
      "|      100|           62|\n",
      "|      100|           50|\n",
      "|      100|           43|\n",
      "|      100|           48|\n",
      "|      100|           58|\n",
      "|      100|           58|\n",
      "|      100|           62|\n",
      "|      100|           45|\n",
      "|      100|           47|\n",
      "|      100|           60|\n",
      "|      100|           57|\n",
      "|      100|           44|\n",
      "|      100|           47|\n",
      "|      100|           66|\n",
      "|      100|           65|\n",
      "|      100|           66|\n",
      "|      100|           42|\n",
      "|      100|           63|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select specific columns from DataFrame\n",
    "df_select_cols = df1['server_id', 'session_count']\n",
    "df_select_cols.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "001097fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49889"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract sample of data, without replacement\n",
    "df1_sample = df1.sample(withReplacement=False, fraction=0.1)\n",
    "df1_sample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "283585c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|\n",
      "|           0.86|03/05/2019 08:06:16|       0.09|      101|           93|\n",
      "|           0.61|03/05/2019 08:06:17|       0.12|      102|           71|\n",
      "|           0.64|03/05/2019 08:06:19|       0.32|      103|           96|\n",
      "|           0.84|03/05/2019 08:06:21|       0.36|      104|           94|\n",
      "|           0.54|03/05/2019 08:06:23|       0.38|      105|           74|\n",
      "|            0.4|03/05/2019 08:06:24|       0.39|      106|           43|\n",
      "|           0.64|03/05/2019 08:06:26|       0.55|      107|           56|\n",
      "|           0.62|03/05/2019 08:06:28|       0.41|      108|           86|\n",
      "|            0.7|03/05/2019 08:06:29|       0.59|      109|           77|\n",
      "|           0.68|03/05/2019 08:06:31|       0.44|      110|           47|\n",
      "|           0.48|03/05/2019 08:06:33|       0.25|      111|           70|\n",
      "|           0.71|03/05/2019 08:06:34|       0.27|      112|           86|\n",
      "|           0.69|03/05/2019 08:06:36|       0.38|      113|           71|\n",
      "|           0.48|03/05/2019 08:06:38|       0.48|      114|           52|\n",
      "|           0.78|03/05/2019 08:06:40|       0.22|      115|           62|\n",
      "|            0.4|03/05/2019 08:06:41|       0.53|      116|           51|\n",
      "|           0.71|03/05/2019 08:06:43|       0.61|      117|           60|\n",
      "|           0.78|03/05/2019 08:06:45|       0.45|      118|           68|\n",
      "|           0.51|03/05/2019 08:06:46|       0.49|      119|           53|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sort data by column\n",
    "df1_sort = df1.sort(\"event_datetime\")\n",
    "df1_sort.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25303365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc1|          31|\n",
      "|03/04/2019 19:53:06|       loc1|          26|\n",
      "|03/04/2019 19:58:06|       loc1|          31|\n",
      "|03/04/2019 20:03:06|       loc1|          26|\n",
      "|03/04/2019 20:08:06|       loc1|          28|\n",
      "|03/04/2019 20:13:06|       loc1|          27|\n",
      "|03/04/2019 20:18:06|       loc1|          30|\n",
      "|03/04/2019 20:23:06|       loc1|          28|\n",
      "|03/04/2019 20:28:06|       loc1|          28|\n",
      "|03/04/2019 20:33:06|       loc1|          27|\n",
      "|03/04/2019 20:38:06|       loc1|          30|\n",
      "|03/04/2019 20:43:06|       loc1|          32|\n",
      "|03/04/2019 20:48:06|       loc1|          26|\n",
      "|03/04/2019 20:53:06|       loc1|          30|\n",
      "|03/04/2019 20:58:06|       loc1|          26|\n",
      "|03/04/2019 21:03:06|       loc1|          28|\n",
      "|03/04/2019 21:08:06|       loc1|          27|\n",
      "|03/04/2019 21:13:06|       loc1|          28|\n",
      "|03/04/2019 21:18:06|       loc1|          27|\n",
      "|03/04/2019 21:23:06|       loc1|          26|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter data by column\n",
    "df2_filter = df2.filter(df2[\"location_id\"] == 'loc1')\n",
    "df2_filter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6870168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|      loc22| 1000|\n",
      "|      loc31| 1000|\n",
      "|      loc82| 1000|\n",
      "|      loc90| 1000|\n",
      "|     loc118| 1000|\n",
      "|      loc39| 1000|\n",
      "|      loc75| 1000|\n",
      "|     loc122| 1000|\n",
      "|      loc24| 1000|\n",
      "|      loc30| 1000|\n",
      "|     loc105| 1000|\n",
      "|      loc96| 1000|\n",
      "|     loc102| 1000|\n",
      "|      loc18| 1000|\n",
      "|      loc27| 1000|\n",
      "|     loc143| 1000|\n",
      "|      loc43| 1000|\n",
      "|     loc123| 1000|\n",
      "|      loc15| 1000|\n",
      "|      loc48| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate data and get count\n",
    "df2_agg_count = df2.groupBy(\"location_id\").count()\n",
    "df2_agg_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f08eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|location_id|count|\n",
      "+-----------+-----+\n",
      "|       loc0| 1000|\n",
      "|       loc1| 1000|\n",
      "|      loc10| 1000|\n",
      "|     loc100| 1000|\n",
      "|     loc101| 1000|\n",
      "|     loc102| 1000|\n",
      "|     loc103| 1000|\n",
      "|     loc104| 1000|\n",
      "|     loc105| 1000|\n",
      "|     loc106| 1000|\n",
      "|     loc107| 1000|\n",
      "|     loc108| 1000|\n",
      "|     loc109| 1000|\n",
      "|      loc11| 1000|\n",
      "|     loc110| 1000|\n",
      "|     loc111| 1000|\n",
      "|     loc112| 1000|\n",
      "|     loc113| 1000|\n",
      "|     loc114| 1000|\n",
      "|     loc115| 1000|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate data and get count, with ordering\n",
    "df2_agg_count = df2.groupBy(\"location_id\").count().orderBy(\"location_id\")\n",
    "df2_agg_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c88815e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|avg(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|      loc22|           28.251|\n",
      "|      loc31|           25.196|\n",
      "|      loc82|           27.355|\n",
      "|      loc90|           23.216|\n",
      "|     loc118|           24.219|\n",
      "|      loc39|           25.199|\n",
      "|      loc75|           23.209|\n",
      "|     loc122|            32.36|\n",
      "|      loc24|           31.109|\n",
      "|      loc30|           30.211|\n",
      "|     loc105|           26.217|\n",
      "|      loc96|           28.138|\n",
      "|     loc102|           30.327|\n",
      "|      loc18|           30.198|\n",
      "|      loc27|           31.239|\n",
      "|     loc143|           28.213|\n",
      "|      loc43|           32.196|\n",
      "|     loc123|           23.424|\n",
      "|      loc15|           32.171|\n",
      "|      loc48|           30.244|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate data and get mean\n",
    "df2_agg_mean = df2.groupBy(\"location_id\").agg({\"temp_celcius\": \"mean\"})\n",
    "df2_agg_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8117d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|location_id|max(temp_celcius)|\n",
      "+-----------+-----------------+\n",
      "|       loc0|               36|\n",
      "|       loc1|               35|\n",
      "|      loc10|               32|\n",
      "|     loc100|               34|\n",
      "|     loc101|               32|\n",
      "|     loc102|               37|\n",
      "|     loc103|               32|\n",
      "|     loc104|               33|\n",
      "|     loc105|               33|\n",
      "|     loc106|               34|\n",
      "|     loc107|               40|\n",
      "|     loc108|               39|\n",
      "|     loc109|               31|\n",
      "|      loc11|               32|\n",
      "|     loc110|               33|\n",
      "|     loc111|               38|\n",
      "|     loc112|               40|\n",
      "|     loc113|               37|\n",
      "|     loc114|               36|\n",
      "|     loc115|               30|\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate data and get mean\n",
    "df2_agg_mean = df2.groupBy(\"location_id\").agg({\"temp_celcius\": \"max\"})\n",
    "df2_agg_mean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21a0e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|location_id|count(1)|\n",
      "+-----------+--------+\n",
      "|       loc0|    1000|\n",
      "|       loc1|    1000|\n",
      "|      loc10|    1000|\n",
      "|     loc100|    1000|\n",
      "|     loc101|    1000|\n",
      "|     loc102|    1000|\n",
      "|     loc103|    1000|\n",
      "|     loc104|    1000|\n",
      "|     loc105|    1000|\n",
      "|     loc106|    1000|\n",
      "|     loc107|    1000|\n",
      "|     loc108|    1000|\n",
      "|     loc109|    1000|\n",
      "|      loc11|    1000|\n",
      "|     loc110|    1000|\n",
      "|     loc111|    1000|\n",
      "|     loc112|    1000|\n",
      "|     loc113|    1000|\n",
      "|     loc114|    1000|\n",
      "|     loc115|    1000|\n",
      "+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aggregate data and get count, using agg()\n",
    "df2_agg_count = df2.groupBy(\"location_id\").agg({\"*\": \"count\"}).orderBy(\"location_id\")\n",
    "df2_agg_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "388e4e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/05/2019 02:33:06|       loc0|          29|\n",
      "|03/05/2019 04:28:06|       loc0|          32|\n",
      "|03/05/2019 07:18:06|       loc0|          29|\n",
      "|03/05/2019 20:03:06|       loc0|          29|\n",
      "|03/06/2019 21:48:06|       loc0|          32|\n",
      "|03/07/2019 16:18:06|       loc0|          28|\n",
      "|03/05/2019 07:38:06|       loc1|          29|\n",
      "|03/05/2019 08:33:06|       loc1|          29|\n",
      "|03/06/2019 12:08:06|       loc1|          31|\n",
      "|03/07/2019 09:18:06|       loc1|          31|\n",
      "|03/07/2019 13:03:06|       loc1|          28|\n",
      "|03/07/2019 21:18:06|       loc1|          32|\n",
      "|03/04/2019 21:13:06|       loc2|          28|\n",
      "|03/06/2019 20:18:06|       loc2|          31|\n",
      "|03/07/2019 23:03:06|       loc2|          30|\n",
      "|03/04/2019 21:38:06|       loc3|          25|\n",
      "|03/06/2019 07:43:06|       loc3|          22|\n",
      "|03/06/2019 16:13:06|       loc3|          23|\n",
      "|03/06/2019 20:33:06|       loc3|          23|\n",
      "|03/07/2019 13:58:07|       loc3|          23|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate rows\n",
    "df_no_dups = df2.drop_duplicates()\n",
    "df_no_dups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "812c87f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|         event_date|location_id|temp_celcius|\n",
      "+-------------------+-----------+------------+\n",
      "|03/04/2019 19:48:06|       loc0|          29|\n",
      "|03/04/2019 19:48:06|       loc1|          31|\n",
      "|03/04/2019 19:48:08|      loc10|          26|\n",
      "|03/04/2019 19:48:25|     loc100|          32|\n",
      "|03/04/2019 19:48:25|     loc101|          24|\n",
      "|03/04/2019 19:48:25|     loc102|          29|\n",
      "|03/04/2019 19:48:25|     loc103|          23|\n",
      "|03/04/2019 19:48:26|     loc104|          24|\n",
      "|03/04/2019 19:48:26|     loc105|          30|\n",
      "|03/04/2019 19:48:26|     loc106|          25|\n",
      "|03/04/2019 19:48:26|     loc107|          35|\n",
      "|03/04/2019 19:48:26|     loc108|          39|\n",
      "|03/04/2019 19:48:27|     loc109|          24|\n",
      "|03/04/2019 19:48:08|      loc11|          28|\n",
      "|03/04/2019 19:48:27|     loc110|          26|\n",
      "|03/04/2019 19:48:27|     loc111|          35|\n",
      "|03/04/2019 19:48:27|     loc112|          32|\n",
      "|03/04/2019 19:48:27|     loc113|          30|\n",
      "|03/04/2019 19:48:27|     loc114|          28|\n",
      "|03/04/2019 19:48:28|     loc115|          23|\n",
      "+-------------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop rows based on duplicate values of chosen column\n",
    "df_no_dups = df2.drop_duplicates([\"location_id\"])\n",
    "df_no_dups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c818fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+-------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|new_col|\n",
      "+---------------+-------------------+-----------+---------+-------------+-------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|   23.5|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|   21.5|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|   31.0|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|   25.0|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|   21.5|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|   24.0|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|   29.0|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|   29.0|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|   31.0|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|   22.5|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|   23.5|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|   30.0|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|   28.5|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|   22.0|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|   23.5|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|   33.0|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|   32.5|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|   33.0|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|   21.0|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|   31.5|\n",
      "+---------------+-------------------+-----------+---------+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add column to DataFrame 1\n",
    "df_new_col = df1.withColumn(\"new_col\", df1['session_count']/2)\n",
    "df_new_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3844de02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|na_col|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|  null|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|  null|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|  null|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|  null|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|  null|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|  null|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|  null|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|  null|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|  null|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|  null|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|  null|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|  null|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|  null|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|  null|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|  null|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|  null|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|  null|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|  null|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|  null|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|  null|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add column to DataFrame 2\n",
    "df_na = df1.withColumn(\"na_col\", lit(None).cast(StringType()))\n",
    "df_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d01e77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|na_col|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|     A|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|     A|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|     A|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|     A|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|     A|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|     A|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|     A|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|     A|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|     A|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|     A|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|     A|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|     A|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|     A|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|     A|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|     A|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|     A|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|     A|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|     A|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|     A|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|     A|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# replace nulls with a given value\n",
    "df_no_na = df_na.fillna(\"A\")\n",
    "df_no_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3499a014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|na_col|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "|           0.57|03/05/2019 08:06:14|       0.51|      100|           47|     A|\n",
      "|           0.47|03/05/2019 08:11:14|       0.62|      100|           43|     A|\n",
      "|           0.56|03/05/2019 08:16:14|       0.57|      100|           62|     A|\n",
      "|           0.57|03/05/2019 08:21:14|       0.56|      100|           50|     A|\n",
      "|           0.35|03/05/2019 08:26:14|       0.46|      100|           43|     A|\n",
      "|           0.41|03/05/2019 08:31:14|       0.58|      100|           48|     A|\n",
      "|           0.57|03/05/2019 08:36:14|       0.35|      100|           58|     A|\n",
      "|           0.41|03/05/2019 08:41:14|        0.4|      100|           58|     A|\n",
      "|           0.53|03/05/2019 08:46:14|       0.35|      100|           62|     A|\n",
      "|           0.51|03/05/2019 08:51:14|        0.6|      100|           45|     A|\n",
      "|           0.32|03/05/2019 08:56:14|       0.37|      100|           47|     A|\n",
      "|           0.62|03/05/2019 09:01:14|       0.59|      100|           60|     A|\n",
      "|           0.66|03/05/2019 09:06:14|       0.72|      100|           57|     A|\n",
      "|           0.54|03/05/2019 09:11:14|       0.54|      100|           44|     A|\n",
      "|           0.29|03/05/2019 09:16:14|        0.4|      100|           47|     A|\n",
      "|           0.43|03/05/2019 09:21:14|       0.68|      100|           66|     A|\n",
      "|           0.49|03/05/2019 09:26:14|       0.66|      100|           65|     A|\n",
      "|           0.64|03/05/2019 09:31:14|       0.55|      100|           66|     A|\n",
      "|           0.42|03/05/2019 09:36:14|        0.6|      100|           42|     A|\n",
      "|           0.55|03/05/2019 09:41:14|       0.59|      100|           63|     A|\n",
      "+---------------+-------------------+-----------+---------+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenate similar DataFrames\n",
    "df_na = df_no_na.union(df_na)\n",
    "df_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "761b61cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with na values\n",
    "df_no_na = df_na.na.drop()\n",
    "df_no_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548161a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save DataFrame as CSV\n",
    "df1.write.csv(\"df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fa19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save DataFrame as CSV\n",
    "df1.write.json(\"df1.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
